{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2181757-6fb0-4dd4-87ff-88358f862f5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e87149c-03c7-459a-8fe6-6c4b0bee83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a wrapper class for the BERT model\n",
    "class BertWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "# Load a pre-trained BERT model and tokenizer from Hugging Face\n",
    "model_name = 'bert-base-uncased'\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Wrap the BERT model\n",
    "model = BertWrapper(bert_model)\n",
    "\n",
    "# Create a SummaryWriter instance\n",
    "writer = SummaryWriter('runs/huggingface_model_visualization')\n",
    "\n",
    "# Prepare a dummy input\n",
    "text = \"Hello, this is a sample input for visualization.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Add the model graph to TensorBoard\n",
    "writer.add_graph(model, (inputs.input_ids, inputs.attention_mask))\n",
    "\n",
    "# Close the writer\n",
    "writer.close()\n",
    "\n",
    "print(f\"Model graph for {model_name} has been added to TensorBoard.\")\n",
    "print(\"Run 'tensorboard --logdir=runs' to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c5e714-6a2a-458f-9666-095bebaea12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method _wrapped_call_impl in module torch.nn.modules.module:\n",
      "\n",
      "_wrapped_call_impl(*args, **kwargs) method of __main__.BertWrapper instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81670df-f658-4537-81a4-6ca6bcd4ccb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Resnet tensor board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d77faf-e5b1-4d99-8642-7d430b51d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger cat\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\", trust_remote_code=True)\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5866cf5a-f669-4781-8267-f37d6d9f8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3cb11b-3ac5-4a50-b08f-7da5ed6eab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajab\\miniconda3\\envs\\py3_120\\Lib\\site-packages\\transformers\\models\\resnet\\modeling_resnet.py:91: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.model(pixel_values)\n",
    "        return outputs.logits\n",
    "\n",
    "\n",
    "mw = ModelWrapper(model)\n",
    "\n",
    "writer = SummaryWriter('.runs/huggingface_model_visualization')\n",
    "\n",
    "writer.add_graph(mw, inputs['pixel_values'])\n",
    "\n",
    "writer.close()\n",
    "print(f\"Model graph for ResNet-50 has been added to TensorBoard.\")\n",
    "print(\"Run 'tensorboard --logdir=.runs' to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d2937-cb8f-40a5-ba2c-0d4232ad689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3c8212-f913-4da8-be6d-65bb8ecfdf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T14:29:52.663933Z",
     "iopub.status.busy": "2024-08-19T14:29:52.652012Z",
     "iopub.status.idle": "2024-08-19T14:29:52.675094Z",
     "shell.execute_reply": "2024-08-19T14:29:52.674308Z",
     "shell.execute_reply.started": "2024-08-19T14:29:52.663691Z"
    },
    "tags": []
   },
   "source": [
    "# stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6dad2a-62d2-4ead-9751-ecbe438496b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "# Set up the pipeline\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"  # You can change this to your specific model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Set up TensorBoard writer\n",
    "writer = SummaryWriter('runs/stable_diffusion_visualization')\n",
    "\n",
    "# Your input prompt\n",
    "prompt = \"a photo of an astronaut drinking cola on moon\"\n",
    "\n",
    "# Function to log tensor to TensorBoard\n",
    "def log_tensor(name, tensor, step):\n",
    "    if tensor.ndim == 4:  # For image tensors\n",
    "        writer.add_images(name, tensor, step)\n",
    "    else:\n",
    "        writer.add_histogram(name, tensor, step)\n",
    "    # writer.add_graph(name, tensor, \t)\n",
    "\n",
    "# Run the pipeline with logging\n",
    "with torch.no_grad():\n",
    "    # Tokenize and encode text\n",
    "    text_inputs = pipe.tokenizer(prompt, padding=\"max_length\", max_length=pipe.tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "    text_embeddings = pipe.text_encoder(text_inputs.input_ids.to(pipe.device))[0]\n",
    "    log_tensor(\"text_embeddings\", text_embeddings, 0)\n",
    "\n",
    "    # Generate random noise\n",
    "    latents = torch.randn((1, pipe.unet.in_channels, 64, 64)).to(pipe.device)\n",
    "    log_tensor(\"initial_latents\", latents, 0)\n",
    "\n",
    "    # Denoise the image\n",
    "    for i, t in enumerate(pipe.scheduler.timesteps):\n",
    "        # Expand the latents for classifier-free guidance\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "        # Predict the noise residual\n",
    "        noise_pred = pipe.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "        log_tensor(f\"noise_pred_{i}\", noise_pred, i)\n",
    "\n",
    "        # Perform guidance\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + pipe.guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "        # Compute the previous noisy sample x_t -> x_t-1\n",
    "        latents = pipe.scheduler.step(noise_pred, t, latents).prev_sample\n",
    "        log_tensor(f\"latents_{i}\", latents, i)\n",
    "\n",
    "    # Decode the image\n",
    "    image = pipe.vae.decode(latents / pipe.vae.config.scaling_factor, return_dict=False)[0]\n",
    "    log_tensor(\"final_image\", image, len(pipe.scheduler.timesteps))\n",
    "\n",
    "    # Save the final image\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "    image = (image * 255).round().astype(\"uint8\")\n",
    "    torchvision.utils.save_image(torch.from_numpy(image).permute(2, 0, 1) / 255., \"generated_image.png\")\n",
    "\n",
    "writer.close()\n",
    "print(\"Visualization data has been written to TensorBoard. Run 'tensorboard --logdir=runs' to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf2461-29c6-4afd-bdb5-9e4d332825aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a0f95-d350-4d01-b75c-d8381a8cb947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26126dec-615e-454f-8dc1-44708c51093e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0df3e-7926-41d3-97a6-8ecdc2769221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127bfb3-68b1-4f0e-b59d-3dd77855372a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd5e06-90a3-4b14-a632-568498ff9d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5410c-7d1c-4c5c-b8c4-e5f00a497753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbd07a-ea31-45fe-82ba-70b70b114406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a87d21-0ea3-4681-911f-aa35280f357a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84200d5e-15e3-42fb-b562-013322220bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
